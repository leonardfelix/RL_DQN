cartpole1:
  env_id: CartPole-v1
  checkpoint: ""
  prior_data: ""
  replay_memory_size: 10000
  batch_size: 64
  epsilon_start: 1.0
  epsilon_decay: 0.9995
  epsilon_end: 0.05
  network_sync_rate: 100
  discount_factor: 0.99
  lr: 0.001
  hidden_dims: 32
  maximum_reward_stop: 100000
  enable_double_DQN: True
  enable_dueling_DQN: True
  prioritised_replay: False
  


flappybird1:
  env_id: FlappyBird-v0
  checkpoint: ""
  prior_data: ""
  replay_memory_size: 100000
  batch_size: 64
  epsilon_start: 1.0
  epsilon_decay: 0.9995
  epsilon_end: 0.05
  network_sync_rate: 100
  discount_factor: 0.99
  lr: 0.001
  hidden_dims: 256
  maximum_reward_stop: 100000
  enable_double_DQN: True
  enable_dueling_DQN: True
  alpha: 0.6 # priorty exponent (0 = uniform, 1 = highest priority first)
  beta: 0.4 # importance-sampling correction (0 = no correction, 1 = perfect correction)
  beta_increment: 0.0001 # rate of beta increase per episode

## use hidden dueling 64
# cartpole1:
#   env_id: CartPole-v1
#   checkpoint: ""
#   replay_memory_size: 10000
#   batch_size: 32
#   epsilon_start: 1.0
#   epsilon_decay: 0.9995
#   epsilon_end: 0.05
#   network_sync_rate: 100
#   discount_factor: 0.99
#   lr: 0.001
#   hidden_dims: 126
#   maximum_reward_stop: 100000
#   enable_double_DQN: False
#   enable_dueling_DQN: True

# flappybird1:
#   env_id: FlappyBird-v0
#   checkpoint: ""
#   prior_data: ""
#   replay_memory_size: 100000
#   batch_size: 32
#   epsilon_start: 1.0
#   epsilon_decay: 0.9955
#   epsilon_end: 0.01
#   network_sync_rate: 100
#   discount_factor: 0.99
#   lr: 0.00005
#   hidden_dims: 256
#   maximum_reward_stop: 10000
#   enable_double_DQN: True
#   enable_dueling_DQN: True
#   prioritised_replay: True